{"cells":[{"cell_type":"markdown","metadata":{"id":"6r02rz2eBev0"},"source":["# Main Task: Feature Analysis and Classification Preparation\n","\n","This notebook is dedicated to analyzing and preparing the deep features provided for the main task. We aim to understand the structure of the data to create an effective validation and training setup for our classifier. The main steps in this notebook include:\n","\n","1. **Loading and Exploring the Dataset**: We start by loading the provided CSV files that contain deep features extracted from pretrained image recognition models.\n","2. **Understanding Data Structure**: We inspect each dataset to understand its columns, data types, and how the data is organized. This is crucial for ensuring that our next steps in data processing, such as creating a validation set and training a classifier, are done accurately.\n"]},{"cell_type":"markdown","metadata":{"id":"ErohB6wKBev4"},"source":["## Step 1: Loading and Exploring Data\n","\n","### Datasets Overview\n","\n","We have five CSV files located in the `features` folder:\n","\n","- **Training Set 1** (`train_efficientformerv2_s0.snap_dist_in1k.csv`): Contains features extracted from the training images.\n","- **Training Set 2** (`train_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.csv`): Contains features extracted from another set of training images.\n","- **Test Set 1** (`val_efficientformerv2_s0.snap_dist_in1k.csv`): Contains validation set features.\n","- **Test Set 2** (`val_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.csv`): Contains features for another validation/test set.\n","- **Additional Test Set** (`v2_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.csv`): Contains features for the second test set.\n","\n","Each CSV file likely contains the deep features extracted from each image, labels, and identifiers for each image.\n","\n","In this step, we load the files and inspect them to ensure the structure is appropriate for further analysis.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_DQ2n3oBev5","outputId":"582266f6-3fc6-4e36-b018-e9ebfd30addf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Set 1 Info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1281167 entries, 0 to 1281166\n","Columns: 178 entries, Unnamed: 0 to 175\n","dtypes: float64(176), int64(2)\n","memory usage: 1.7 GB\n","None\n","\n","Training Set 2 Info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1281167 entries, 0 to 1281166\n","Columns: 1027 entries, Unnamed: 0 to 1023\n","dtypes: float64(1024), int64(2), object(1)\n","memory usage: 9.8+ GB\n","None\n","\n","Validation Set 1 Info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50000 entries, 0 to 49999\n","Columns: 178 entries, Unnamed: 0 to 175\n","dtypes: float64(176), int64(2)\n","memory usage: 67.9 MB\n","None\n","\n","Validation Set 2 Info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50000 entries, 0 to 49999\n","Columns: 1027 entries, Unnamed: 0 to 1023\n","dtypes: float64(1024), int64(2), object(1)\n","memory usage: 391.8+ MB\n","None\n","\n","Test Set 2 Info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Columns: 1027 entries, Unnamed: 0 to 1023\n","dtypes: float64(1024), int64(2), object(1)\n","memory usage: 78.4+ MB\n","None\n"]}],"source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","# Define dataset file names\n","dataset_files = {\n","    \"train_1\": \"train_efficientformerv2_s0.snap_dist_in1k.csv\",\n","    \"train_2\": \"train_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.csv\",\n","    \"val_1\": \"val_efficientformerv2_s0.snap_dist_in1k.csv\",\n","    \"val_2\": \"val_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.csv\",\n","    \"test_2\": \"v2_eva02_large_patch14_448.mim_m38m_ft_in22k_in1k.csv\"\n","}\n","\n","# Construct dynamic paths based on the current working directory\n","current_dir = os.getcwd()\n","dataset_paths = {key: os.path.join(current_dir, filename) for key, filename in dataset_files.items()}\n","\n","# Check if each dataset file exists in the current directory\n","for key, path in dataset_paths.items():\n","    if not os.path.isfile(path):\n","        print(f\"Warning: {path} not found in the current directory.\")\n","\n","\n","# Load the datasets\n","data_train_1 = pd.read_csv(dataset_paths[\"train_1\"])\n","data_train_2 = pd.read_csv(dataset_paths[\"train_2\"])\n","data_val_1 = pd.read_csv(dataset_paths[\"val_1\"])\n","data_val_2 = pd.read_csv(dataset_paths[\"val_2\"])\n","data_test_2 = pd.read_csv(dataset_paths[\"test_2\"])\n","\n","# Display basic information about each dataset\n","print(\"Training Set 1 Info:\")\n","print(data_train_1.info())\n","print(\"\\nTraining Set 2 Info:\")\n","print(data_train_2.info())\n","print(\"\\nValidation Set 1 Info:\")\n","print(data_val_1.info())\n","print(\"\\nValidation Set 2 Info:\")\n","print(data_val_2.info())\n","print(\"\\nTest Set 2 Info:\")\n","print(data_test_2.info())\n"]},{"cell_type":"markdown","metadata":{"id":"WUS414vEBev8"},"source":["## Step 2: Initial Data Exploration\n","\n","After loading the datasets, we take a look at the first few rows of each dataset to get an understanding of their structure, columns, and data types. This helps in planning further steps for data preprocessing and model training.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AjaoQbrzBev8","outputId":"2cd8fff0-d65a-4e2d-8c93-44a99f5cfc33"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Set 1 Preview:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>label</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>...</th>\n","      <th>166</th>\n","      <th>167</th>\n","      <th>168</th>\n","      <th>169</th>\n","      <th>170</th>\n","      <th>171</th>\n","      <th>172</th>\n","      <th>173</th>\n","      <th>174</th>\n","      <th>175</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>-0.691965</td>\n","      <td>0.429367</td>\n","      <td>-1.474302</td>\n","      <td>0.676748</td>\n","      <td>-0.679136</td>\n","      <td>1.773247</td>\n","      <td>0.260406</td>\n","      <td>-0.141160</td>\n","      <td>...</td>\n","      <td>0.569029</td>\n","      <td>0.213042</td>\n","      <td>0.718620</td>\n","      <td>-0.004285</td>\n","      <td>1.413921</td>\n","      <td>-0.053185</td>\n","      <td>-0.393623</td>\n","      <td>0.347522</td>\n","      <td>0.005400</td>\n","      <td>-0.184637</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-0.864601</td>\n","      <td>0.225054</td>\n","      <td>-1.293910</td>\n","      <td>1.875433</td>\n","      <td>-0.813366</td>\n","      <td>0.625775</td>\n","      <td>0.448439</td>\n","      <td>0.238565</td>\n","      <td>...</td>\n","      <td>0.137239</td>\n","      <td>0.315176</td>\n","      <td>0.299817</td>\n","      <td>0.355286</td>\n","      <td>1.491020</td>\n","      <td>0.201894</td>\n","      <td>-0.959820</td>\n","      <td>-0.054513</td>\n","      <td>-0.949135</td>\n","      <td>0.300053</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>-1.114701</td>\n","      <td>0.494977</td>\n","      <td>-0.773202</td>\n","      <td>1.348325</td>\n","      <td>-0.835751</td>\n","      <td>0.959926</td>\n","      <td>0.449962</td>\n","      <td>0.213483</td>\n","      <td>...</td>\n","      <td>-0.132967</td>\n","      <td>0.949368</td>\n","      <td>1.327500</td>\n","      <td>0.409213</td>\n","      <td>1.100111</td>\n","      <td>-0.566179</td>\n","      <td>-1.280500</td>\n","      <td>0.157962</td>\n","      <td>-0.318487</td>\n","      <td>0.740788</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>-1.137314</td>\n","      <td>0.436045</td>\n","      <td>-1.150390</td>\n","      <td>1.017622</td>\n","      <td>-0.283604</td>\n","      <td>1.202694</td>\n","      <td>-0.215836</td>\n","      <td>0.578007</td>\n","      <td>...</td>\n","      <td>-0.086298</td>\n","      <td>0.021069</td>\n","      <td>0.179697</td>\n","      <td>0.937757</td>\n","      <td>1.602664</td>\n","      <td>0.030761</td>\n","      <td>-1.030833</td>\n","      <td>0.509741</td>\n","      <td>-0.697458</td>\n","      <td>-0.093973</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>-0.635249</td>\n","      <td>0.734545</td>\n","      <td>-2.242432</td>\n","      <td>1.215234</td>\n","      <td>-1.398403</td>\n","      <td>1.077606</td>\n","      <td>-0.204856</td>\n","      <td>0.831079</td>\n","      <td>...</td>\n","      <td>0.153358</td>\n","      <td>0.362587</td>\n","      <td>0.374471</td>\n","      <td>0.606531</td>\n","      <td>1.153050</td>\n","      <td>0.331303</td>\n","      <td>-0.237664</td>\n","      <td>-0.195951</td>\n","      <td>-0.912587</td>\n","      <td>0.430202</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 178 columns</p>\n","</div>"],"text/plain":["   Unnamed: 0  label         0         1         2         3         4  \\\n","0           0      0 -0.691965  0.429367 -1.474302  0.676748 -0.679136   \n","1           1      0 -0.864601  0.225054 -1.293910  1.875433 -0.813366   \n","2           2      0 -1.114701  0.494977 -0.773202  1.348325 -0.835751   \n","3           3      0 -1.137314  0.436045 -1.150390  1.017622 -0.283604   \n","4           4      0 -0.635249  0.734545 -2.242432  1.215234 -1.398403   \n","\n","          5         6         7  ...       166       167       168       169  \\\n","0  1.773247  0.260406 -0.141160  ...  0.569029  0.213042  0.718620 -0.004285   \n","1  0.625775  0.448439  0.238565  ...  0.137239  0.315176  0.299817  0.355286   \n","2  0.959926  0.449962  0.213483  ... -0.132967  0.949368  1.327500  0.409213   \n","3  1.202694 -0.215836  0.578007  ... -0.086298  0.021069  0.179697  0.937757   \n","4  1.077606 -0.204856  0.831079  ...  0.153358  0.362587  0.374471  0.606531   \n","\n","        170       171       172       173       174       175  \n","0  1.413921 -0.053185 -0.393623  0.347522  0.005400 -0.184637  \n","1  1.491020  0.201894 -0.959820 -0.054513 -0.949135  0.300053  \n","2  1.100111 -0.566179 -1.280500  0.157962 -0.318487  0.740788  \n","3  1.602664  0.030761 -1.030833  0.509741 -0.697458 -0.093973  \n","4  1.153050  0.331303 -0.237664 -0.195951 -0.912587  0.430202  \n","\n","[5 rows x 178 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Training Set 2 Preview:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>path</th>\n","      <th>label</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>...</th>\n","      <th>1014</th>\n","      <th>1015</th>\n","      <th>1016</th>\n","      <th>1017</th>\n","      <th>1018</th>\n","      <th>1019</th>\n","      <th>1020</th>\n","      <th>1021</th>\n","      <th>1022</th>\n","      <th>1023</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>train/n01440764/n01440764_18.JPEG</td>\n","      <td>0</td>\n","      <td>1.711095</td>\n","      <td>0.835201</td>\n","      <td>-0.127168</td>\n","      <td>1.379754</td>\n","      <td>0.101688</td>\n","      <td>-0.627872</td>\n","      <td>-0.366791</td>\n","      <td>...</td>\n","      <td>-0.285088</td>\n","      <td>0.582474</td>\n","      <td>0.095038</td>\n","      <td>-0.287412</td>\n","      <td>-1.839582</td>\n","      <td>-0.744467</td>\n","      <td>-0.777846</td>\n","      <td>1.115427</td>\n","      <td>-1.401509</td>\n","      <td>0.358023</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>train/n01440764/n01440764_36.JPEG</td>\n","      <td>0</td>\n","      <td>2.163767</td>\n","      <td>-0.111684</td>\n","      <td>-0.936583</td>\n","      <td>1.670834</td>\n","      <td>1.100557</td>\n","      <td>-1.264050</td>\n","      <td>-0.962655</td>\n","      <td>...</td>\n","      <td>0.257141</td>\n","      <td>0.831347</td>\n","      <td>-0.104257</td>\n","      <td>-0.409997</td>\n","      <td>-2.520433</td>\n","      <td>-0.687198</td>\n","      <td>0.369469</td>\n","      <td>1.027798</td>\n","      <td>-0.807802</td>\n","      <td>1.865396</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>train/n01440764/n01440764_37.JPEG</td>\n","      <td>0</td>\n","      <td>1.225150</td>\n","      <td>-1.156221</td>\n","      <td>0.710573</td>\n","      <td>0.918564</td>\n","      <td>-0.913152</td>\n","      <td>-1.974395</td>\n","      <td>-1.073880</td>\n","      <td>...</td>\n","      <td>-0.416749</td>\n","      <td>-0.059723</td>\n","      <td>-0.564677</td>\n","      <td>0.101635</td>\n","      <td>-0.382511</td>\n","      <td>-0.265244</td>\n","      <td>1.252536</td>\n","      <td>1.459591</td>\n","      <td>-1.113860</td>\n","      <td>2.192563</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>train/n01440764/n01440764_39.JPEG</td>\n","      <td>0</td>\n","      <td>1.832900</td>\n","      <td>0.728762</td>\n","      <td>0.678453</td>\n","      <td>1.176897</td>\n","      <td>1.388000</td>\n","      <td>-0.123888</td>\n","      <td>0.026504</td>\n","      <td>...</td>\n","      <td>1.287073</td>\n","      <td>-0.630051</td>\n","      <td>0.952620</td>\n","      <td>-0.919523</td>\n","      <td>-1.231753</td>\n","      <td>-1.724055</td>\n","      <td>-0.858167</td>\n","      <td>-0.994872</td>\n","      <td>-0.495612</td>\n","      <td>0.107676</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>train/n01440764/n01440764_44.JPEG</td>\n","      <td>0</td>\n","      <td>1.173622</td>\n","      <td>-1.540397</td>\n","      <td>0.732026</td>\n","      <td>1.334288</td>\n","      <td>0.141878</td>\n","      <td>-1.421545</td>\n","      <td>-0.298131</td>\n","      <td>...</td>\n","      <td>-0.381300</td>\n","      <td>0.359091</td>\n","      <td>0.423626</td>\n","      <td>1.800759</td>\n","      <td>-1.225449</td>\n","      <td>-1.042220</td>\n","      <td>2.244787</td>\n","      <td>1.667592</td>\n","      <td>-0.787097</td>\n","      <td>2.120671</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1027 columns</p>\n","</div>"],"text/plain":["   Unnamed: 0                               path  label         0         1  \\\n","0           0  train/n01440764/n01440764_18.JPEG      0  1.711095  0.835201   \n","1           1  train/n01440764/n01440764_36.JPEG      0  2.163767 -0.111684   \n","2           2  train/n01440764/n01440764_37.JPEG      0  1.225150 -1.156221   \n","3           3  train/n01440764/n01440764_39.JPEG      0  1.832900  0.728762   \n","4           4  train/n01440764/n01440764_44.JPEG      0  1.173622 -1.540397   \n","\n","          2         3         4         5         6  ...      1014      1015  \\\n","0 -0.127168  1.379754  0.101688 -0.627872 -0.366791  ... -0.285088  0.582474   \n","1 -0.936583  1.670834  1.100557 -1.264050 -0.962655  ...  0.257141  0.831347   \n","2  0.710573  0.918564 -0.913152 -1.974395 -1.073880  ... -0.416749 -0.059723   \n","3  0.678453  1.176897  1.388000 -0.123888  0.026504  ...  1.287073 -0.630051   \n","4  0.732026  1.334288  0.141878 -1.421545 -0.298131  ... -0.381300  0.359091   \n","\n","       1016      1017      1018      1019      1020      1021      1022  \\\n","0  0.095038 -0.287412 -1.839582 -0.744467 -0.777846  1.115427 -1.401509   \n","1 -0.104257 -0.409997 -2.520433 -0.687198  0.369469  1.027798 -0.807802   \n","2 -0.564677  0.101635 -0.382511 -0.265244  1.252536  1.459591 -1.113860   \n","3  0.952620 -0.919523 -1.231753 -1.724055 -0.858167 -0.994872 -0.495612   \n","4  0.423626  1.800759 -1.225449 -1.042220  2.244787  1.667592 -0.787097   \n","\n","       1023  \n","0  0.358023  \n","1  1.865396  \n","2  2.192563  \n","3  0.107676  \n","4  2.120671  \n","\n","[5 rows x 1027 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Validation Set 1 Preview:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>label</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>...</th>\n","      <th>166</th>\n","      <th>167</th>\n","      <th>168</th>\n","      <th>169</th>\n","      <th>170</th>\n","      <th>171</th>\n","      <th>172</th>\n","      <th>173</th>\n","      <th>174</th>\n","      <th>175</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.809346</td>\n","      <td>-0.738084</td>\n","      <td>-0.859336</td>\n","      <td>1.296571</td>\n","      <td>-1.325332</td>\n","      <td>0.919664</td>\n","      <td>1.109796</td>\n","      <td>-1.407456</td>\n","      <td>...</td>\n","      <td>-0.290378</td>\n","      <td>-0.242527</td>\n","      <td>1.649247</td>\n","      <td>1.414449</td>\n","      <td>1.513692</td>\n","      <td>-1.321456</td>\n","      <td>-0.629092</td>\n","      <td>0.725050</td>\n","      <td>0.693541</td>\n","      <td>0.915292</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-0.882923</td>\n","      <td>1.150681</td>\n","      <td>-1.641869</td>\n","      <td>2.107567</td>\n","      <td>-0.591841</td>\n","      <td>0.610033</td>\n","      <td>-0.110605</td>\n","      <td>-0.966672</td>\n","      <td>...</td>\n","      <td>-0.126001</td>\n","      <td>0.801338</td>\n","      <td>1.134217</td>\n","      <td>0.907576</td>\n","      <td>0.686816</td>\n","      <td>-1.109138</td>\n","      <td>-1.316739</td>\n","      <td>0.017125</td>\n","      <td>0.281246</td>\n","      <td>0.055396</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>-0.231489</td>\n","      <td>0.955537</td>\n","      <td>-2.243777</td>\n","      <td>1.122168</td>\n","      <td>1.282349</td>\n","      <td>0.232199</td>\n","      <td>0.277746</td>\n","      <td>0.809463</td>\n","      <td>...</td>\n","      <td>0.826562</td>\n","      <td>1.066999</td>\n","      <td>-0.270203</td>\n","      <td>1.131028</td>\n","      <td>1.537412</td>\n","      <td>0.506395</td>\n","      <td>-0.365762</td>\n","      <td>-0.433311</td>\n","      <td>-0.258090</td>\n","      <td>-0.098776</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>-1.696757</td>\n","      <td>1.343956</td>\n","      <td>-2.390712</td>\n","      <td>0.910955</td>\n","      <td>-0.259735</td>\n","      <td>0.495845</td>\n","      <td>0.988126</td>\n","      <td>-0.179933</td>\n","      <td>...</td>\n","      <td>-0.855595</td>\n","      <td>0.463232</td>\n","      <td>0.156201</td>\n","      <td>1.160251</td>\n","      <td>0.468894</td>\n","      <td>-1.026086</td>\n","      <td>-0.767089</td>\n","      <td>-0.527841</td>\n","      <td>0.160261</td>\n","      <td>-0.072648</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>-0.541759</td>\n","      <td>0.601003</td>\n","      <td>-1.195804</td>\n","      <td>0.442355</td>\n","      <td>-1.620797</td>\n","      <td>1.057665</td>\n","      <td>-0.488956</td>\n","      <td>-0.903029</td>\n","      <td>...</td>\n","      <td>0.009232</td>\n","      <td>0.509935</td>\n","      <td>0.362473</td>\n","      <td>0.264628</td>\n","      <td>0.472355</td>\n","      <td>-0.313989</td>\n","      <td>-2.603466</td>\n","      <td>0.267026</td>\n","      <td>-0.218627</td>\n","      <td>0.437477</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 178 columns</p>\n","</div>"],"text/plain":["   Unnamed: 0  label         0         1         2         3         4  \\\n","0           0      0  0.809346 -0.738084 -0.859336  1.296571 -1.325332   \n","1           1      0 -0.882923  1.150681 -1.641869  2.107567 -0.591841   \n","2           2      0 -0.231489  0.955537 -2.243777  1.122168  1.282349   \n","3           3      0 -1.696757  1.343956 -2.390712  0.910955 -0.259735   \n","4           4      0 -0.541759  0.601003 -1.195804  0.442355 -1.620797   \n","\n","          5         6         7  ...       166       167       168       169  \\\n","0  0.919664  1.109796 -1.407456  ... -0.290378 -0.242527  1.649247  1.414449   \n","1  0.610033 -0.110605 -0.966672  ... -0.126001  0.801338  1.134217  0.907576   \n","2  0.232199  0.277746  0.809463  ...  0.826562  1.066999 -0.270203  1.131028   \n","3  0.495845  0.988126 -0.179933  ... -0.855595  0.463232  0.156201  1.160251   \n","4  1.057665 -0.488956 -0.903029  ...  0.009232  0.509935  0.362473  0.264628   \n","\n","        170       171       172       173       174       175  \n","0  1.513692 -1.321456 -0.629092  0.725050  0.693541  0.915292  \n","1  0.686816 -1.109138 -1.316739  0.017125  0.281246  0.055396  \n","2  1.537412  0.506395 -0.365762 -0.433311 -0.258090 -0.098776  \n","3  0.468894 -1.026086 -0.767089 -0.527841  0.160261 -0.072648  \n","4  0.472355 -0.313989 -2.603466  0.267026 -0.218627  0.437477  \n","\n","[5 rows x 178 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Validation Set 2 Preview:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>path</th>\n","      <th>label</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>...</th>\n","      <th>1014</th>\n","      <th>1015</th>\n","      <th>1016</th>\n","      <th>1017</th>\n","      <th>1018</th>\n","      <th>1019</th>\n","      <th>1020</th>\n","      <th>1021</th>\n","      <th>1022</th>\n","      <th>1023</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>val/n01440764/ILSVRC2012_val_00000293.JPEG</td>\n","      <td>0</td>\n","      <td>1.662802</td>\n","      <td>-0.213297</td>\n","      <td>1.074171</td>\n","      <td>1.530290</td>\n","      <td>-0.439417</td>\n","      <td>-1.262904</td>\n","      <td>0.078828</td>\n","      <td>...</td>\n","      <td>0.394033</td>\n","      <td>0.627909</td>\n","      <td>-0.750575</td>\n","      <td>1.301602</td>\n","      <td>-0.239263</td>\n","      <td>1.909301</td>\n","      <td>-0.203759</td>\n","      <td>1.757995</td>\n","      <td>-0.432645</td>\n","      <td>0.570522</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>val/n01440764/ILSVRC2012_val_00002138.JPEG</td>\n","      <td>0</td>\n","      <td>0.613421</td>\n","      <td>-0.298935</td>\n","      <td>0.014120</td>\n","      <td>-0.006895</td>\n","      <td>0.650840</td>\n","      <td>-1.648001</td>\n","      <td>-0.281046</td>\n","      <td>...</td>\n","      <td>-0.781071</td>\n","      <td>0.991205</td>\n","      <td>-0.184955</td>\n","      <td>1.285053</td>\n","      <td>-0.904435</td>\n","      <td>0.059819</td>\n","      <td>0.590151</td>\n","      <td>1.227890</td>\n","      <td>-0.403007</td>\n","      <td>1.603119</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>val/n01440764/ILSVRC2012_val_00003014.JPEG</td>\n","      <td>0</td>\n","      <td>1.485904</td>\n","      <td>-0.155148</td>\n","      <td>-1.219090</td>\n","      <td>0.789956</td>\n","      <td>0.734070</td>\n","      <td>-1.023040</td>\n","      <td>0.607749</td>\n","      <td>...</td>\n","      <td>-0.172693</td>\n","      <td>1.473490</td>\n","      <td>1.185195</td>\n","      <td>1.525165</td>\n","      <td>-1.152541</td>\n","      <td>-0.202304</td>\n","      <td>0.292297</td>\n","      <td>1.931547</td>\n","      <td>-1.359611</td>\n","      <td>1.279764</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>val/n01440764/ILSVRC2012_val_00006697.JPEG</td>\n","      <td>0</td>\n","      <td>1.357525</td>\n","      <td>-1.472001</td>\n","      <td>-0.714301</td>\n","      <td>0.783935</td>\n","      <td>0.101140</td>\n","      <td>-0.594126</td>\n","      <td>-0.941238</td>\n","      <td>...</td>\n","      <td>-0.222315</td>\n","      <td>0.336519</td>\n","      <td>0.212243</td>\n","      <td>0.841153</td>\n","      <td>-1.061117</td>\n","      <td>0.281507</td>\n","      <td>-0.122996</td>\n","      <td>1.637755</td>\n","      <td>-0.303253</td>\n","      <td>0.515429</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>val/n01440764/ILSVRC2012_val_00007197.JPEG</td>\n","      <td>0</td>\n","      <td>-0.271945</td>\n","      <td>-1.363063</td>\n","      <td>0.114712</td>\n","      <td>0.678845</td>\n","      <td>0.562754</td>\n","      <td>-1.678377</td>\n","      <td>-0.662571</td>\n","      <td>...</td>\n","      <td>-0.288426</td>\n","      <td>0.814253</td>\n","      <td>-0.329616</td>\n","      <td>1.066108</td>\n","      <td>-0.860438</td>\n","      <td>-0.165122</td>\n","      <td>0.468664</td>\n","      <td>1.610508</td>\n","      <td>-0.425671</td>\n","      <td>2.031233</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1027 columns</p>\n","</div>"],"text/plain":["   Unnamed: 0                                        path  label         0  \\\n","0           0  val/n01440764/ILSVRC2012_val_00000293.JPEG      0  1.662802   \n","1           1  val/n01440764/ILSVRC2012_val_00002138.JPEG      0  0.613421   \n","2           2  val/n01440764/ILSVRC2012_val_00003014.JPEG      0  1.485904   \n","3           3  val/n01440764/ILSVRC2012_val_00006697.JPEG      0  1.357525   \n","4           4  val/n01440764/ILSVRC2012_val_00007197.JPEG      0 -0.271945   \n","\n","          1         2         3         4         5         6  ...      1014  \\\n","0 -0.213297  1.074171  1.530290 -0.439417 -1.262904  0.078828  ...  0.394033   \n","1 -0.298935  0.014120 -0.006895  0.650840 -1.648001 -0.281046  ... -0.781071   \n","2 -0.155148 -1.219090  0.789956  0.734070 -1.023040  0.607749  ... -0.172693   \n","3 -1.472001 -0.714301  0.783935  0.101140 -0.594126 -0.941238  ... -0.222315   \n","4 -1.363063  0.114712  0.678845  0.562754 -1.678377 -0.662571  ... -0.288426   \n","\n","       1015      1016      1017      1018      1019      1020      1021  \\\n","0  0.627909 -0.750575  1.301602 -0.239263  1.909301 -0.203759  1.757995   \n","1  0.991205 -0.184955  1.285053 -0.904435  0.059819  0.590151  1.227890   \n","2  1.473490  1.185195  1.525165 -1.152541 -0.202304  0.292297  1.931547   \n","3  0.336519  0.212243  0.841153 -1.061117  0.281507 -0.122996  1.637755   \n","4  0.814253 -0.329616  1.066108 -0.860438 -0.165122  0.468664  1.610508   \n","\n","       1022      1023  \n","0 -0.432645  0.570522  \n","1 -0.403007  1.603119  \n","2 -1.359611  1.279764  \n","3 -0.303253  0.515429  \n","4 -0.425671  2.031233  \n","\n","[5 rows x 1027 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Test Set 2 Preview:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>path</th>\n","      <th>label</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>...</th>\n","      <th>1014</th>\n","      <th>1015</th>\n","      <th>1016</th>\n","      <th>1017</th>\n","      <th>1018</th>\n","      <th>1019</th>\n","      <th>1020</th>\n","      <th>1021</th>\n","      <th>1022</th>\n","      <th>1023</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>imagenetv2-matched-frequency-format-val/0/7e4a...</td>\n","      <td>0</td>\n","      <td>1.609683</td>\n","      <td>-1.695807</td>\n","      <td>0.505799</td>\n","      <td>0.854063</td>\n","      <td>-0.552767</td>\n","      <td>-0.870220</td>\n","      <td>-0.666728</td>\n","      <td>...</td>\n","      <td>0.290859</td>\n","      <td>-0.594491</td>\n","      <td>-0.771617</td>\n","      <td>1.249772</td>\n","      <td>-1.593839</td>\n","      <td>-0.245009</td>\n","      <td>1.531979</td>\n","      <td>1.749554</td>\n","      <td>-2.090416</td>\n","      <td>3.374129</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>imagenetv2-matched-frequency-format-val/0/8e13...</td>\n","      <td>0</td>\n","      <td>1.676880</td>\n","      <td>-1.029967</td>\n","      <td>0.220793</td>\n","      <td>0.042956</td>\n","      <td>-1.021416</td>\n","      <td>-2.215872</td>\n","      <td>-0.876766</td>\n","      <td>...</td>\n","      <td>0.430398</td>\n","      <td>0.393080</td>\n","      <td>-2.114492</td>\n","      <td>0.997730</td>\n","      <td>-0.638402</td>\n","      <td>0.632086</td>\n","      <td>0.258975</td>\n","      <td>2.417562</td>\n","      <td>-1.662887</td>\n","      <td>2.638886</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>imagenetv2-matched-frequency-format-val/0/58fb...</td>\n","      <td>0</td>\n","      <td>1.464891</td>\n","      <td>-1.955225</td>\n","      <td>-0.801968</td>\n","      <td>-0.186100</td>\n","      <td>-0.842917</td>\n","      <td>-1.540113</td>\n","      <td>-1.049285</td>\n","      <td>...</td>\n","      <td>0.702250</td>\n","      <td>-0.300494</td>\n","      <td>-0.705781</td>\n","      <td>0.418966</td>\n","      <td>-1.657272</td>\n","      <td>0.319704</td>\n","      <td>1.462022</td>\n","      <td>0.821431</td>\n","      <td>-1.347082</td>\n","      <td>3.177216</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>imagenetv2-matched-frequency-format-val/0/64f6...</td>\n","      <td>0</td>\n","      <td>1.881878</td>\n","      <td>-1.645641</td>\n","      <td>0.217000</td>\n","      <td>3.114708</td>\n","      <td>0.766505</td>\n","      <td>-1.099833</td>\n","      <td>-0.699149</td>\n","      <td>...</td>\n","      <td>-0.026364</td>\n","      <td>-0.431337</td>\n","      <td>-0.225326</td>\n","      <td>0.558948</td>\n","      <td>-0.548851</td>\n","      <td>0.157238</td>\n","      <td>0.864088</td>\n","      <td>1.231380</td>\n","      <td>-1.315329</td>\n","      <td>2.947850</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>imagenetv2-matched-frequency-format-val/0/6612...</td>\n","      <td>0</td>\n","      <td>0.070927</td>\n","      <td>-2.795652</td>\n","      <td>-0.555790</td>\n","      <td>1.117381</td>\n","      <td>-1.113867</td>\n","      <td>-2.519658</td>\n","      <td>-0.160650</td>\n","      <td>...</td>\n","      <td>-0.449849</td>\n","      <td>0.854443</td>\n","      <td>-0.446073</td>\n","      <td>1.269782</td>\n","      <td>-1.177952</td>\n","      <td>-0.904718</td>\n","      <td>0.218977</td>\n","      <td>2.304722</td>\n","      <td>-1.318533</td>\n","      <td>3.040294</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1027 columns</p>\n","</div>"],"text/plain":["   Unnamed: 0                                               path  label  \\\n","0           0  imagenetv2-matched-frequency-format-val/0/7e4a...      0   \n","1           1  imagenetv2-matched-frequency-format-val/0/8e13...      0   \n","2           2  imagenetv2-matched-frequency-format-val/0/58fb...      0   \n","3           3  imagenetv2-matched-frequency-format-val/0/64f6...      0   \n","4           4  imagenetv2-matched-frequency-format-val/0/6612...      0   \n","\n","          0         1         2         3         4         5         6  ...  \\\n","0  1.609683 -1.695807  0.505799  0.854063 -0.552767 -0.870220 -0.666728  ...   \n","1  1.676880 -1.029967  0.220793  0.042956 -1.021416 -2.215872 -0.876766  ...   \n","2  1.464891 -1.955225 -0.801968 -0.186100 -0.842917 -1.540113 -1.049285  ...   \n","3  1.881878 -1.645641  0.217000  3.114708  0.766505 -1.099833 -0.699149  ...   \n","4  0.070927 -2.795652 -0.555790  1.117381 -1.113867 -2.519658 -0.160650  ...   \n","\n","       1014      1015      1016      1017      1018      1019      1020  \\\n","0  0.290859 -0.594491 -0.771617  1.249772 -1.593839 -0.245009  1.531979   \n","1  0.430398  0.393080 -2.114492  0.997730 -0.638402  0.632086  0.258975   \n","2  0.702250 -0.300494 -0.705781  0.418966 -1.657272  0.319704  1.462022   \n","3 -0.026364 -0.431337 -0.225326  0.558948 -0.548851  0.157238  0.864088   \n","4 -0.449849  0.854443 -0.446073  1.269782 -1.177952 -0.904718  0.218977   \n","\n","       1021      1022      1023  \n","0  1.749554 -2.090416  3.374129  \n","1  2.417562 -1.662887  2.638886  \n","2  0.821431 -1.347082  3.177216  \n","3  1.231380 -1.315329  2.947850  \n","4  2.304722 -1.318533  3.040294  \n","\n","[5 rows x 1027 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["# Display the first few rows of each dataset\n","print(\"Training Set 1 Preview:\")\n","display(data_train_1.head())\n","\n","print(\"\\nTraining Set 2 Preview:\")\n","display(data_train_2.head())\n","\n","print(\"\\nValidation Set 1 Preview:\")\n","display(data_val_1.head())\n","\n","print(\"\\nValidation Set 2 Preview:\")\n","display(data_val_2.head())\n","\n","print(\"\\nTest Set 2 Preview:\")\n","display(data_test_2.head())\n"]},{"cell_type":"markdown","metadata":{"id":"dIYTPR5mBev8"},"source":["## Step 3: Creating a Validation Split from the Training Data\n","\n","To effectively tune our classifier, we need a separate validation set that’s distinct from both the original validation and test sets. In this step, we’ll:\n","\n","1. **Define the Split Ratio**: We will split the original training data into a new training set and validation set using an 80-20 split.\n","2. **Stratified Sampling**: We'll stratify based on the `label` column (assuming there is a label column) to ensure the label distribution is preserved in both the training and validation sets.\n","3. **Check Split**: Finally, we’ll verify the split by displaying the `.info()` for both new datasets.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R8FkbOI4Bev9","outputId":"2840cce5-1b19-4c23-f226-c11bd7b693c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["New Training Set 1 (Efficientformer) Info:\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 1024933 entries, 581117 to 39038\n","Columns: 178 entries, Unnamed: 0 to 175\n","dtypes: float64(176), int64(2)\n","memory usage: 1.4 GB\n","None\n","\n","New Validation Set (Efficientformer) Info:\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 256234 entries, 1059862 to 628576\n","Columns: 178 entries, Unnamed: 0 to 175\n","dtypes: float64(176), int64(2)\n","memory usage: 349.9 MB\n","None\n","\n","New Training Set 2 (Eva02) Info:\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 1024933 entries, 581117 to 39038\n","Columns: 1027 entries, Unnamed: 0 to 1023\n","dtypes: float64(1024), int64(2), object(1)\n","memory usage: 7.9+ GB\n","None\n","\n","New Validation Set (Eva02) Info:\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 256234 entries, 1059862 to 628576\n","Columns: 1027 entries, Unnamed: 0 to 1023\n","dtypes: float64(1024), int64(2), object(1)\n","memory usage: 2.0+ GB\n","None\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","# Assuming the 'label' column exists in both training datasets, otherwise adjust the column name as necessary.\n","# Split Training Set 1 (efficientformer) into new training and validation sets\n","train_1_data, val_1_data = train_test_split(data_train_1, test_size=0.2, stratify=data_train_1['label'], random_state=42)\n","\n","# Split Training Set 2 (eva02) into new training and validation sets\n","train_2_data, val_2_data = train_test_split(data_train_2, test_size=0.2, stratify=data_train_2['label'], random_state=42)\n","\n","# Verify the splits\n","print(\"New Training Set 1 (Efficientformer) Info:\")\n","print(train_1_data.info())\n","print(\"\\nNew Validation Set (Efficientformer) Info:\")\n","print(val_1_data.info())\n","\n","print(\"\\nNew Training Set 2 (Eva02) Info:\")\n","print(train_2_data.info())\n","print(\"\\nNew Validation Set (Eva02) Info:\")\n","print(val_2_data.info())\n"]},{"cell_type":"markdown","metadata":{"id":"b9HslYMyBev9"},"source":["## Step 4: Saving the Split Datasets\n","\n","Once the datasets are split, it’s essential to save them to disk for later use. This step ensures that if the kernel crashes, we won’t need to re-run the splitting process.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lbQX1W0cBev9"},"outputs":[],"source":["# Define file paths for saving the split datasets\n","'''split_paths = {\n","    \"train_1_split\": \"/Users/arsh/Documents/f/A3/A/Big Data A3/ImageAnalyticsAssignment/data/features/train_1_split.csv\",\n","    \"val_1_split\": \"/Users/arsh/Documents/f/A3/A/Big Data A3/ImageAnalyticsAssignment/data/features/val_1_split.csv\",\n","    \"train_2_split\": \"/Users/arsh/Documents/f/A3/A/Big Data A3/ImageAnalyticsAssignment/data/features/train_2_split.csv\",\n","    \"val_2_split\": \"/Users/arsh/Documents/f/A3/A/Big Data A3/ImageAnalyticsAssignment/data/features/val_2_split.csv\"\n","}\n","\n","# Save the datasets\n","train_1_data.to_csv(split_paths[\"train_1_split\"], index=False)\n","val_1_data.to_csv(split_paths[\"val_1_split\"], index=False)\n","train_2_data.to_csv(split_paths[\"train_2_split\"], index=False)\n","val_2_data.to_csv(split_paths[\"val_2_split\"], index=False)\n","\n","print(\"Datasets successfully saved!\")'''\n"]},{"cell_type":"markdown","metadata":{"id":"MbcOKs06Bev-"},"source":["## Step 5: Save Split Datasets in Organized Subfolder\n","\n","To keep the project files organized, we’ll save the newly created split datasets in a subfolder named `split_data` within the `data/features` directory.\n","\n","### Steps:\n","1. **Create the Subfolder**: We check if the `split_data` folder exists; if not, we create it.\n","2. **Define File Paths**: We set file paths for each split dataset within the `split_data` folder.\n","3. **Save Split Data**: We use `to_csv()` to save each split dataset (train and validation sets for both `train_1` and `train_2`) into their respective files in the `split_data` folder.\n","\n","This setup ensures the split datasets are neatly stored and accessible for later steps.\n","\n","Output confirmation:\n","The console will confirm the successful creation of the directory and the saving of datasets.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rodwG07_Bev-","outputId":"bb5a58a6-652d-4a80-9740-ac5fac1ab61d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Directory '/Users/arsh/Documents/f/A3/A/Big Data A3/ImageAnalyticsAssignment/data/features/split_data' created.\n","Datasets successfully saved in the 'split_data' subfolder!\n"]}],"source":["import os\n","\n","# Define the relative subfolder path for split data\n","split_folder_relative = \"data/features/split_data\"\n","\n","# Construct the full path based on the current working directory\n","current_dir = os.getcwd()\n","split_folder_path = os.path.join(current_dir, split_folder_relative)\n","\n","# Create the subfolder if it doesn't already exist\n","if not os.path.exists(split_folder_path):\n","    os.makedirs(split_folder_path)\n","    print(f\"Directory '{split_folder_path}' created.\")\n","else:\n","    print(f\"Directory '{split_folder_path}' already exists.\")\n","\n","# Define the file paths for saving the split datasets within the new subfolder\n","split_paths = {\n","    \"train_1_split\": os.path.join(split_folder_path, \"train_1_split.csv\"),\n","    \"val_1_split\": os.path.join(split_folder_path, \"val_1_split.csv\"),\n","    \"train_2_split\": os.path.join(split_folder_path, \"train_2_split.csv\"),\n","    \"val_2_split\": os.path.join(split_folder_path, \"val_2_split.csv\")\n","}\n","\n","# Save the datasets\n","train_1_data.to_csv(split_paths[\"train_1_split\"], index=False)\n","val_1_data.to_csv(split_paths[\"val_1_split\"], index=False)\n","train_2_data.to_csv(split_paths[\"train_2_split\"], index=False)\n","val_2_data.to_csv(split_paths[\"val_2_split\"], index=False)\n","\n","print(\"Datasets successfully saved in the 'split_data' subfolder!\")\n"]},{"cell_type":"markdown","metadata":{"id":"AmyDh-2ABev-"},"source":["## Step 6: Handling Missing Values\n","\n","To ensure data consistency and avoid issues during model training, we will identify and address any missing values in our split datasets. This step is essential for maintaining the quality and reliability of our data:\n","\n","1. **Check for Missing Values**: We will use `.isnull().sum()` on each split dataset to identify columns with missing values. This will allow us to pinpoint specific features that require attention.\n","\n","2. **Handle Missing Values**: Based on the identified columns, we will decide the best approach, whether it’s filling the missing values with the mean, median, or mode, or removing rows if necessary.\n","\n","This step will prepare our datasets for the model-specific preprocessing that will take place in individual model notebooks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTdWujGiBev-","outputId":"57092c5a-e3d4-426b-e1d1-e5184d13e2dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Missing values in Split Train 1:\n","Unnamed: 0    0\n","label         0\n","0             0\n","1             0\n","2             0\n","             ..\n","171           0\n","172           0\n","173           0\n","174           0\n","175           0\n","Length: 178, dtype: int64\n","\n","Missing values in Split Val 1:\n","Unnamed: 0    0\n","label         0\n","0             0\n","1             0\n","2             0\n","             ..\n","171           0\n","172           0\n","173           0\n","174           0\n","175           0\n","Length: 178, dtype: int64\n","\n","Missing values in Split Train 2:\n","Unnamed: 0    0\n","path          0\n","label         0\n","0             0\n","1             0\n","             ..\n","1019          0\n","1020          0\n","1021          0\n","1022          0\n","1023          0\n","Length: 1027, dtype: int64\n","\n","Missing values in Split Val 2:\n","Unnamed: 0    0\n","path          0\n","label         0\n","0             0\n","1             0\n","             ..\n","1019          0\n","1020          0\n","1021          0\n","1022          0\n","1023          0\n","Length: 1027, dtype: int64\n"]}],"source":["# Check for missing values in the split datasets\n","print(\"Missing values in Split Train 1:\")\n","print(train_1_data.isnull().sum())\n","print(\"\\nMissing values in Split Val 1:\")\n","print(val_1_data.isnull().sum())\n","print(\"\\nMissing values in Split Train 2:\")\n","print(train_2_data.isnull().sum())\n","print(\"\\nMissing values in Split Val 2:\")\n","print(val_2_data.isnull().sum())\n","\n","# Fill missing values (if any) with the mean or median, depending on the data type\n","train_1_data.fillna(train_1_data.mean(), inplace=True)\n","val_1_data.fillna(val_1_data.mean(), inplace=True)\n","train_2_data.fillna(train_2_data.mean(), inplace=True)\n","val_2_data.fillna(val_2_data.mean(), inplace=True)\n","\n","print(\"Missing values handled successfully in the split datasets!\")\n"]},{"cell_type":"markdown","metadata":{"id":"HoJozoXXBev_"},"source":["# Final Summary of Data Preparation\n","\n","In this notebook, we completed the following steps to prepare the datasets for modeling:\n","\n","1. **Loaded Datasets**: Imported training, validation, and test datasets for initial analysis.\n","2. **Dataset Exploration**: Checked the structure, columns, data types, and confirmed labels.\n","3. **Data Splitting**: Split the original training sets into new training and validation subsets to support model evaluation.\n","4. **Organized Data Storage**: Saved each split dataset into a designated folder for easy access during model training.\n","\n","The finalized datasets are now stored in the `split_data` folder within the main data directory, ready for further preprocessing or model-specific adjustments as needed.\n"]}],"metadata":{"kernelspec":{"display_name":"main_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}