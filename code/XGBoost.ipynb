{"cells":[{"cell_type":"markdown","metadata":{"id":"k9oeSJgTBdow"},"source":["\n","#### Markdown:\n","In this cell, we:\n","1. **Imported required libraries**: `pandas` for data handling, `XGBClassifier` from `xgboost` for model implementation, and metrics from `sklearn`.\n","2. **Loaded the prepared split datasets**: Reading the CSV files for sampled training and validation sets.\n","3. **Separated features and labels**: `X_train_sample` and `y_train_sample` for training, `X_val` and `y_val` for validation.\n","4. **Verified shapes**: Printed the shapes to ensure consistency and correct data loading.\n","initial setup, and let me know when you're ready to proceed with defining, training, and evaluating the XGBoost model!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvD5F2RRBdo_","outputId":"20a67e83-276f-457e-b201-7bc5068fc22e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sampled Training Features Shape: (1024933, 177)\n","Sampled Training Labels Shape: (1024933,)\n","Validation Features Shape: (256234, 177)\n","Validation Labels Shape: (256234,)\n"]}],"source":["# Import necessary libraries\n","import pandas as pd\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","import os\n","\n","# Define dataset filenames\n","dataset_files = {\n","    \"X_train_sample\": \"split_data/train_1_split.csv\",\n","    \"X_val\": \"split_data/val_1_split.csv\"\n","}\n","\n","# Construct dynamic paths based on the current working directory\n","current_dir = os.getcwd()\n","dataset_paths = {key: os.path.join(current_dir, \"data/features\", filename) for key, filename in dataset_files.items()}\n","\n","# Load the prepared datasets\n","try:\n","    X_train_sample = pd.read_csv(dataset_paths[\"X_train_sample\"])\n","    y_train_sample = X_train_sample.pop('label')\n","\n","    X_val = pd.read_csv(dataset_paths[\"X_val\"])\n","    y_val = X_val.pop('label')\n","except FileNotFoundError as e:\n","    print(f\"File not found: {e}\")\n","\n","\n","# Confirm shapes for training and validation sets\n","print(\"Sampled Training Features Shape:\", X_train_sample.shape)\n","print(\"Sampled Training Labels Shape:\", y_train_sample.shape)\n","print(\"Validation Features Shape:\", X_val.shape)\n","print(\"Validation Labels Shape:\", y_val.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"SwhTXHzmBdpF"},"source":["#### Markdown:\n","In this cell, we:\n","1. **Defined the XGBoost Classifier**:\n","   - Set `random_state` for reproducibility.\n","   - Disabled `use_label_encoder` and specified `eval_metric='mlogloss'` to avoid warnings and optimize multi-class classification.\n","2. **Trained the model**: The classifier is trained using the sampled training dataset.\n","3. **Made predictions**: We generated predictions on the validation dataset.\n","4. **Evaluated the classifier**: Output accuracy and a full classification report including precision, recall, and F1-score for each class.\n","ve run this, let me know, and we’ll proceed to visualizations for further insights."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"437us7ZTBdpI","outputId":"6cb97e87-88f7-4255-e9e5-c0f1aada152d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/envs/main_env/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [08:36:32] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d9k8pmaj4_/croot/xgboost-split_1724073758172/work/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]}],"source":["# Define the XGBoost Classifier with default parameters\n","xgb_clf = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n","\n","# Train the classifier on the sampled training data\n","xgb_clf.fit(X_train_sample, y_train_sample)\n","\n","# Make predictions on the validation data\n","xgb_y_pred = xgb_clf.predict(X_val)\n","\n","# Evaluate the model\n","print(\"XGBoost Classifier Accuracy:\", accuracy_score(y_val, xgb_y_pred))\n","print(\"\\nClassification Report:\\n\", classification_report(y_val, xgb_y_pred))\n"]},{"cell_type":"markdown","metadata":{"id":"6FeLHcONBdpJ"},"source":["### Model Evaluation Metrics\n","\n","In this cell, we calculate and display a set of comprehensive metrics to evaluate the Random Forest model:\n","\n","1. **Accuracy**: The overall percentage of correct predictions.\n","2. **Precision (Weighted)**: The weighted average of precision for all classes, considering class imbalance.\n","3. **Recall (Weighted)**: The weighted average of recall for all classes.\n","4. **F1 Score (Weighted)**: The weighted average of the F1 score for all classes, giving a balance between precision and recall.\n","\n","Finally, we plot a **Confusion Matrix** for a visual breakdown of true vs. predicted labels, providing insights into specific class-level performance.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KLDsVkZxBdpJ"},"outputs":[],"source":["# Display model metrics and classification report for XGBoost\n","\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Step 1: Calculate and display accuracy\n","accuracy_xgb = accuracy_score(y_val, xgb_y_pred)\n","print(f\"XGBoost Classifier Accuracy: {accuracy_xgb:.4f}\")\n","\n","# Step 2: Generate and display classification report\n","xgb_classification_report = classification_report(y_val, xgb_y_pred)\n","print(\"\\nClassification Report:\\n\", xgb_classification_report)\n"]},{"cell_type":"markdown","metadata":{"id":"6xRDp7luBdpK"},"source":["## Visualization\n","1. **Confusion Matrix**:\n","   - Displays the classifier’s accuracy per class.\n","   - Helps identify patterns of misclassification.\n","\n","2. **ROC Curve and AUC**:\n","   - Plots a ROC curve for each class in a one-vs-rest setup.\n","   - The Area Under the Curve (AUC) provides a measure of how well the classifier distinguishes between classes.\n","\n","3. **Feature Importance Plot**:\n","   - Highlights the top 10 most influential features used by the XGBoost classifier.\n","   - This plot helps in understanding which features contributed most to the classification process.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pdthmkBTBdpM"},"outputs":[],"source":["# Import necessary libraries for visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","from xgboost import plot_importance\n","\n","# Step 1: Confusion Matrix\n","conf_matrix = confusion_matrix(y_val, xgb_y_pred)\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n","plt.title(\"Confusion Matrix for XGBoost Classifier\")\n","plt.xlabel(\"Predicted Labels\")\n","plt.ylabel(\"True Labels\")\n","plt.show()\n","\n","# Step 2: ROC Curve and AUC for each class (One-vs-Rest)\n","y_val_binary = label_binarize(y_val, classes=sorted(set(y_val)))\n","xgb_y_pred_proba = xgb_clf.predict_proba(X_val)\n","\n","plt.figure(figsize=(10, 7))\n","for i in range(y_val_binary.shape[1]):\n","    fpr, tpr, _ = roc_curve(y_val_binary[:, i], xgb_y_pred_proba[:, i])\n","    roc_auc = auc(fpr, tpr)\n","    plt.plot(fpr, tpr, label=f\"Class {i} (AUC = {roc_auc:.2f})\")\n","\n","plt.plot([0, 1], [0, 1], \"k--\")\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"XGBoost Classifier ROC Curve (One-vs-Rest)\")\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","# Step 3: Feature Importance Plot\n","plt.figure(figsize=(12, 8))\n","plot_importance(xgb_clf, max_num_features=10, importance_type=\"weight\")\n","plt.title(\"Top 10 Feature Importances for XGBoost Classifier\")\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"8ALCRLfABdpN"},"source":["\n","1. **Displaying Model Accuracy**:\n","   - Shows the overall performance of the XGBoost classifier.\n","\n","2. **Generating and Displaying the Classification Report**:\n","   - Outputs metrics including precision, recall, and f1-score for each class, which provides insights into the model's ability to handle different categories.\n"]}],"metadata":{"kernelspec":{"display_name":"main_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}